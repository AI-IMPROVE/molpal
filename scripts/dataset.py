from argparse import ArgumentParser
from dataclasses import dataclass, field
from pathlib import Path
import pickle
from typing import Optional, Union

import numpy as np
from tqdm import tqdm, trange

from experiment import Experiment, IncompleteExperimentError
from utils import *

@dataclass
class Dataset:
    split: float
    model: str
    metric: str
    N: int
    num_acquired: np.ndarray
    avg: np.ndarray
    smis: np.ndarray
    scores: np.ndarray
    reps: int = field(init=False)
    num_iters: int = field(init=False)

    def __post_init__(self):
        self.reps = len(self.avg)
        self.num_iters = len(self.num_acquired)

        # self.num_acquired = mean_and_sd(self.num_acquired)
        self.avg = mean_and_sd(self.avg)
        self.smis = mean_and_sd(self.smis)
        self.scores = mean_and_sd(self.scores)

    def __str__(self):
        header = f"| {self.split:0.1%} | {self.model.upper()} | {self.metric.upper()} | TOP-{self.N} |"
        border = f"+{'-'*(len(header)-2)}+"

        width = len("Points acquired") + 2
        rows = [
            f"{'Points acquired': >0{width}}: {', '.join(map(str, self.num_acquired))}",
            f"{'Average': >0{width}}: {Dataset.format_reward_array(self.avg, 2)}",
            f"{'SMILES': >0{width}}: {Dataset.format_reward_array(self.smis)}",
            f"{'Scores': >0{width}}: {Dataset.format_reward_array(self.scores)}"
        ]
        
        return "\n".join((border, header, border, *rows))

    @staticmethod
    def format_reward_array(X: np.ndarray, precision: int = 1) -> str:
        means, sds = zip(*X.tolist())
        return ", ".join(
            [
                f"{mean:0.{precision}%} ({sd:0.{precision}%})"
                for mean, sd in zip(means, sds)
            ]
        )

def mean_and_sd(X: np.ndarray) -> np.ndarray:
    Y = np.empty((X.shape[1], 2))
    Y[:, 0], Y[:, 1] = np.nanmean(X, 0), np.nanstd(X, 0)

    return Y

def clip_xss(xss: List[List]) -> np.ndarray:
    n = min(len(xs) for xs in xss)
    xss = [xs[:n] for xs in xss]

    return np.array(xss, float)

def save_dataset(d: Dataset, filepath: Optional[Union[str, Path]] = None):
    pkl_file = filepath or f"{d.split:0.3f}-{d.model}-{d.metric}-top{d.N}.pkl"
    pickle.dump(d, open(pkl_file, "wb"))

    return pkl_file

if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--split", type=float)
    parser.add_argument("--model")
    parser.add_argument("--metric")
    parser.add_argument(
        "-e",
        "--experiments",
        "--expts",
        nargs="+",
        help='the top-level directories generated by MolPAL runs. I.e., the directory with the "data" and "chkpts" directories',
    )
    parser.add_argument(
        "--true-csv", help="a CSV file containing the true scoring data"
    )
    parser.add_argument("--smiles-col", type=int, default=0)
    parser.add_argument("--score-col", type=int, default=1)
    parser.add_argument("--no-title-line", action="store_true", default=False)
    parser.add_argument(
        "--maximize",
        action="store_true",
        default=False,
        help="whether the objective for which you are calculating performance should be maximized.",
    )
    parser.add_argument(
        "-N",
        type=int,
        help="the number of top scores from which to calculate the reward",
    )
    parser.add_argument("-o", "--output", help="the output filepath")

    args = parser.parse_args()
    args.title_line = not args.no_title_line

    d_smi_score = build_true_dict(
        args.true_csv, args.smiles_col, args.score_col, args.title_line, args.maximize
    )
    true_smis_scores = sorted(d_smi_score.items(), key=lambda kv: kv[1], reverse=True)
    true_top_k = true_smis_scores[:args.N]

    rewardss = []
    num_acquired = []
    incomplete_experiments = []
    for expt_dir in tqdm(args.experiments, leave=False):
        e = Experiment(expt_dir)
        rewardss.append(
            [e.calculate_reward(i, true_top_k, False, False)
            for i in range(e.num_iters)]
        )
        num_acquired.append(e.num_acquired)
        try:
            len(e)
        except IncompleteExperimentError:
            incomplete_experiments.append(expt_dir)

    if len(incomplete_experiments) > 0:
        print("There are incomplete experiments!")
        min_iters = min(len(r) for r in rewardss)
        rewardss = [r[:min_iters] for r in rewardss]
        print(
            f"Results will for dataset will be truncated to shortest experiment ({min_iters})."
        )

    R = np.array(rewardss)
    N_a = np.array(num_acquired)
    if len(R.shape) != 3:
        R = clip_xss(rewardss)
        N_a = clip_xss(num_acquired)

    d = Dataset(
        args.split,
        args.model,
        args.metric,
        args.N,
        N_a.mean(0).astype(int),
        R[:,:,0],
        R[:,:,1],
        R[:,:,2],
    )

    print(d)
    if args.output:
        print(f"Saved dataset to {save_dataset(d, args.output)}")
